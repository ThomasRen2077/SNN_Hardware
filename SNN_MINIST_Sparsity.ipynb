{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "XzSfwwPUKDdr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torchvision.datasets import DatasetFolder\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train_mnist = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),           # Resize to 32x32\n",
        "    transforms.RandomCrop(32, padding=4),  # Same augmentation as CIFAR-10\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel grayscale\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),  # MNIST specific normalization\n",
        "])\n",
        "\n",
        "transform_test_mnist = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to 32x32\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel grayscale\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),  # MNIST specific normalization\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root=\"./\", train=True, download=True, transform=transform_train_mnist)\n",
        "testset = torchvision.datasets.MNIST(root=\"./\", train=False, download=True, transform=transform_test_mnist)"
      ],
      "metadata": {
        "id": "m2-CL71AKHf2"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Spike(torch.autograd.Function):\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(ctx, input, threshold):\n",
        "      # your code starts here\n",
        "      ctx.save_for_backward(input)\n",
        "      # ctx.threshold = threshold\n",
        "      return (input > threshold).float()\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "      # your code starts here\n",
        "      input, = ctx.saved_tensors\n",
        "\n",
        "      grad_input = grad_output\n",
        "\n",
        "      surrogate_grad = (1 / (1 + torch.abs(input)) ** 2)\n",
        "      return grad_input * surrogate_grad, None\n",
        "\n",
        "class LIF(nn.Module):\n",
        "    def __init__(self, thre:float = 1.0, tau:float = 0.5, delta_th: float = 1.0):\n",
        "        super(LIF, self).__init__()\n",
        "        self.thre = thre\n",
        "        self.tau = tau\n",
        "        self.delta_th = delta_th  # Increment to threshold after each spike\n",
        "        self.membrane_potential = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        batch_size, time, channels, height, width = x.size()\n",
        "        # Initialize membrane potential and threshold\n",
        "        membrane_potential = torch.zeros_like(x[:, 0, :, :, :])\n",
        "        threshold = torch.full_like(membrane_potential, self.thre)  # Starting threshold for all neurons\n",
        "\n",
        "        spikes = torch.zeros_like(x)\n",
        "        for t in range(x.size(1)):\n",
        "            membrane_potential = membrane_potential * self.tau + x[:, t, :, :, :]\n",
        "            spikes[:, t, :, :, :] = Spike.apply(membrane_potential, threshold)\n",
        "            membrane_potential = membrane_potential * (1 - spikes[:, t, :, :, :])\n",
        "\n",
        "            # Increase the threshold where spikes occur and reset slowly\n",
        "            threshold += self.delta_th * spikes[:, t, :, :, :]  # Increment where spikes occurred\n",
        "            threshold = torch.max(threshold * 0.99, torch.full_like(threshold, self.thre))  # Decay toward base threshold\n",
        "\n",
        "        return spikes\n",
        "\n",
        "\n",
        "class ConvLIF(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(ConvLIF, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.lif = LIF()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, time, channels, height, width = x.size()\n",
        "        reshape_x = x.view(batch_size * time, channels, height, width)\n",
        "        conv_out = self.conv(reshape_x)\n",
        "        _, _, new_height, new_width = conv_out.size()\n",
        "        new_out_channels = self.conv.weight.shape[0]\n",
        "        reshape_conv = conv_out.view(batch_size, time, new_out_channels, new_height, new_width)\n",
        "        return self.lif(reshape_conv)"
      ],
      "metadata": {
        "id": "6xcpcyfmKNl1"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAvgPool2d(nn.Module):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "      super().__init__(*args, **kwargs)\n",
        "      self.module = nn.AvgPool2d(2)\n",
        "\n",
        "  def forward(self, x_seq: torch.Tensor):\n",
        "      y_shape = [x_seq.shape[0], x_seq.shape[1]]\n",
        "      y_seq = self.module(x_seq.flatten(0, 1).contiguous())\n",
        "      y_shape.extend(y_seq.shape[1:])\n",
        "      return y_seq.view(y_shape)"
      ],
      "metadata": {
        "id": "__g34FJyKT8Y"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVGG(nn.Module):\n",
        "  def __init__(self, *args, **kwargs) -> None:\n",
        "     super().__init__(*args, **kwargs)\n",
        "\n",
        "     pool = SAvgPool2d()\n",
        "     self.classifier = nn.Linear(2048 * T, 10)\n",
        "\n",
        "     self.conv1 = ConvLIF(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "     self.conv2 = ConvLIF(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "     self.conv4 = ConvLIF(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "     self.conv5 = ConvLIF(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "     self.conv7 = ConvLIF(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "     self.conv8 = ConvLIF(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "     # your code starts here (convolutional layers)\n",
        "     self.model = nn.Sequential(\n",
        "         # Layer 1: ConvLIF\n",
        "         self.conv1,\n",
        "         # Layer 2: ConvLIF\n",
        "         self.conv2,\n",
        "         # Layer 3: Average Pool\n",
        "         pool,\n",
        "         # Layer 4: ConvLIF\n",
        "         self.conv4,\n",
        "         # Layer 5: ConvLIF\n",
        "         self.conv5,\n",
        "         # Layer 6: Average Pool\n",
        "         pool,\n",
        "         # Layer 7: ConvLIF\n",
        "         self.conv7,\n",
        "         # Layer 8: ConvLIF\n",
        "         self.conv8,\n",
        "         # Layer 9: Average Pool\n",
        "         pool,\n",
        "         nn.Flatten(),\n",
        "         self.classifier\n",
        "     )\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "QfC_c3COKVAs"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "metadata": {
        "id": "bimIC4jsKXZk"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "\n",
        "# Time steps\n",
        "T = 4\n",
        "\n",
        "# Define the model\n",
        "model = SVGG().cuda()\n",
        "\n",
        "# Define the data loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size, num_workers=2, pin_memory=True, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size, num_workers=2, pin_memory=True, shuffle=False)\n",
        "print(f\"Number of batches of training: {len(trainloader)} | number of batches of test: {len(testloader)}\")\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vnyvbq07KZqB",
        "outputId": "a9eb485d-8c0c-46bf-d248-ac3a00838b03"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches of training: 469 | number of batches of test: 79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(epochs):\n",
        "  print(\"Training\")\n",
        "  model.train()\n",
        "  train_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, (images, target) in enumerate(tqdm(trainloader)):\n",
        "    images = images.cuda()\n",
        "    target = target.cuda()\n",
        "\n",
        "    # Step 1: Adding a new time dimension and repeat the image by T times\n",
        "    images = images.unsqueeze(1).repeat(1,T,1,1,1)\n",
        "\n",
        "    # Step 2: Send the reshaped image into the model\n",
        "    output = model(images)\n",
        "\n",
        "    # Step 3: Compute the loss\n",
        "    loss = loss_fn(output, target)\n",
        "\n",
        "    # Step 4: Backward propagation + Update the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    total += target.size(0)\n",
        "    correct += (predicted == target).sum().item()\n",
        "\n",
        "  train_accuracy = 100 * correct / total\n",
        "  # print(f\"Epoch {e+1}, Loss: {train_loss/len(trainloader)}, Accuracy: {train_accuracy}%\")\n",
        "\n",
        "\n",
        "  print(\"Validation\")\n",
        "  model.eval()\n",
        "  val_correct = 0\n",
        "  val_total = 0\n",
        "  for i, (images, target) in enumerate(tqdm(testloader)):\n",
        "    images = images.cuda()\n",
        "    target = target.cuda()\n",
        "\n",
        "    # Step 1: Adding a new time dimension and repeat the image by T times\n",
        "    images = images.unsqueeze(1).repeat(1,T,1,1,1)\n",
        "\n",
        "    # Step 2: Send the reshaped image into the model\n",
        "    output = model(images)\n",
        "\n",
        "    # Step 3: Compute the accuracy based on the accuracy function\n",
        "    _, predicted = torch.max(output, 1)  # Get the index of the max logit\n",
        "    val_total += target.size(0)\n",
        "    val_correct += (predicted == target).sum().item()\n",
        "\n",
        "  top1 = 100 * val_correct / val_total\n",
        "  print(f\"[{e}]/[{epochs}] | Test accuracy = {top1}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD0Jb4nhKb0z",
        "outputId": "2cc890df-0b86-4a48-eed3-9a05ad056b58"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:18<00:00, 25.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 38.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]/[5] | Test accuracy = 87.61%\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:17<00:00, 26.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 39.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]/[5] | Test accuracy = 90.34%\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:18<00:00, 25.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 39.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]/[5] | Test accuracy = 89.9%\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:17<00:00, 26.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 37.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]/[5] | Test accuracy = 94.18%\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:18<00:00, 25.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 37.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4]/[5] | Test accuracy = 95.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}